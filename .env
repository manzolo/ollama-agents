# ============================================================================
# OLLAMA AGENTS - Environment Configuration
# ============================================================================

# ----------------------------------------------------------------------------
# Ollama Service Configuration
# ----------------------------------------------------------------------------
OLLAMA_PORT=11434

# Ollama Host URL (where agents connect to Ollama)
# Use one of the following:
# - http://ollama:11434           → Use local Docker service (default)
# - http://host.docker.internal:11434 → Use Ollama running on host machine
# - http://192.168.1.100:11434    → Use external Ollama server
# - https://your-ollama-api.com   → Use remote Ollama API
OLLAMA_HOST=http://ollama:11434

# ----------------------------------------------------------------------------
# Backoffice Configuration
# ----------------------------------------------------------------------------
BACKOFFICE_PORT=8080

# Host filesystem path (required for Docker socket operations)
# This should be the absolute path to this project on your HOST machine
# Example: /home/username/projects/ollama-agents
# DO NOT use $(pwd) or relative paths - provide the actual absolute path
HOST_PROJECT_ROOT=/home/manzolo/Workspaces/docker/ollama-agents

# Agent URLs (for workflow orchestration)
SWARM_CONVERTER_URL=http://agent-swarm-converter:8000
SWARM_VALIDATOR_URL=http://agent-swarm-validator:8000

# ----------------------------------------------------------------------------
# Swarm Converter Agent Configuration
# ----------------------------------------------------------------------------
SWARM_CONVERTER_PORT=7001
SWARM_CONVERTER_MODEL=llama3.2
SWARM_CONVERTER_TEMPERATURE=0.3
SWARM_CONVERTER_MAX_TOKENS=8192

# ----------------------------------------------------------------------------
# Additional Agents - Add your agent configurations below
# ----------------------------------------------------------------------------

# Example: Code Reviewer Agent
# CODE_REVIEWER_PORT=7002
# CODE_REVIEWER_MODEL=codellama
# CODE_REVIEWER_TEMPERATURE=0.3
# CODE_REVIEWER_MAX_TOKENS=8192

# Example: Documentation Generator Agent
# DOC_GENERATOR_PORT=7003
# DOC_GENERATOR_MODEL=llama3.2
# DOC_GENERATOR_TEMPERATURE=0.7
# DOC_GENERATOR_MAX_TOKENS=4096

# Example: SQL Query Agent
# SQL_AGENT_PORT=7004
# SQL_AGENT_MODEL=llama3.2
# SQL_AGENT_TEMPERATURE=0.2
# SQL_AGENT_MAX_TOKENS=2048

# Example: API Designer Agent
# API_DESIGNER_PORT=7005
# API_DESIGNER_MODEL=llama3.2
# API_DESIGNER_TEMPERATURE=0.6
# API_DESIGNER_MAX_TOKENS=4096

# ----------------------------------------------------------------------------
# Common Settings
# ----------------------------------------------------------------------------

# Default model to use if not specified
DEFAULT_MODEL=llama3.2

# Default temperature (0.0 = deterministic, 1.0 = creative)
DEFAULT_TEMPERATURE=0.7

# Default max tokens
DEFAULT_MAX_TOKENS=4096

# ----------------------------------------------------------------------------
# GPU Configuration
# ----------------------------------------------------------------------------

# Uncomment if using NVIDIA GPUs
# NVIDIA_VISIBLE_DEVICES=all
# NVIDIA_DRIVER_CAPABILITIES=compute,utility

# ----------------------------------------------------------------------------
# Logging Configuration
# ----------------------------------------------------------------------------

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# ----------------------------------------------------------------------------
# Notes
# ----------------------------------------------------------------------------
# - Port range recommendation: 7000-7999 for agent services
# - Temperature guidelines:
#   - 0.0-0.3: Technical, deterministic tasks (code, SQL, conversions)
#   - 0.4-0.7: Balanced tasks (documentation, explanations)
#   - 0.8-1.0: Creative tasks (brainstorming, content generation)
# - Model selection:
#   - llama3.2: General purpose, balanced performance
#   - codellama: Code-focused tasks
#   - mistral: Fast, efficient for simpler tasks
#   - mixtral: Complex reasoning, multi-task
# ============================================================================