# ============================================================================
# OLLAMA AGENTS - Environment Configuration
# ============================================================================

# ----------------------------------------------------------------------------
# Ollama Service Configuration
# ----------------------------------------------------------------------------
OLLAMA_PORT=11434

# ----------------------------------------------------------------------------
# Backoffice Configuration
# ----------------------------------------------------------------------------
BACKOFFICE_PORT=8080
WORKFLOWS_DIR=/app/workflows
FRONTEND_DIR=/app/frontend
AGENT_DEFINITIONS_DIR=/app/agent-definitions
PROJECT_ROOT=/project
SWARM_CONVERTER_URL=http://agent-swarm-converter:8000
SWARM_VALIDATOR_URL=http://agent-swarm-validator:8000

# ----------------------------------------------------------------------------
# Swarm Converter Agent Configuration
# ----------------------------------------------------------------------------
SWARM_CONVERTER_PORT=7001
SWARM_CONVERTER_MODEL=llama3.2
SWARM_CONVERTER_TEMPERATURE=0.3
SWARM_CONVERTER_MAX_TOKENS=8192

# ----------------------------------------------------------------------------
# Additional Agents - Add your agent configurations below
# ----------------------------------------------------------------------------

# Example: Code Reviewer Agent
# CODE_REVIEWER_PORT=7002
# CODE_REVIEWER_MODEL=codellama
# CODE_REVIEWER_TEMPERATURE=0.3
# CODE_REVIEWER_MAX_TOKENS=8192

# Example: Documentation Generator Agent
# DOC_GENERATOR_PORT=7003
# DOC_GENERATOR_MODEL=llama3.2
# DOC_GENERATOR_TEMPERATURE=0.7
# DOC_GENERATOR_MAX_TOKENS=4096

# Example: SQL Query Agent
# SQL_AGENT_PORT=7004
# SQL_AGENT_MODEL=llama3.2
# SQL_AGENT_TEMPERATURE=0.2
# SQL_AGENT_MAX_TOKENS=2048

# Example: API Designer Agent
# API_DESIGNER_PORT=7005
# API_DESIGNER_MODEL=llama3.2
# API_DESIGNER_TEMPERATURE=0.6
# API_DESIGNER_MAX_TOKENS=4096

# ----------------------------------------------------------------------------
# Common Settings
# ----------------------------------------------------------------------------

# Default model to use if not specified
DEFAULT_MODEL=llama3.2

# Default temperature (0.0 = deterministic, 1.0 = creative)
DEFAULT_TEMPERATURE=0.7

# Default max tokens
DEFAULT_MAX_TOKENS=4096

# ----------------------------------------------------------------------------
# GPU Configuration
# ----------------------------------------------------------------------------

# Uncomment if using NVIDIA GPUs
# NVIDIA_VISIBLE_DEVICES=all
# NVIDIA_DRIVER_CAPABILITIES=compute,utility

# ----------------------------------------------------------------------------
# Logging Configuration
# ----------------------------------------------------------------------------

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# ----------------------------------------------------------------------------
# Notes
# ----------------------------------------------------------------------------
# - Port range recommendation: 7000-7999 for agent services
# - Temperature guidelines:
#   - 0.0-0.3: Technical, deterministic tasks (code, SQL, conversions)
#   - 0.4-0.7: Balanced tasks (documentation, explanations)
#   - 0.8-1.0: Creative tasks (brainstorming, content generation)
# - Model selection:
#   - llama3.2: General purpose, balanced performance
#   - codellama: Code-focused tasks
#   - mistral: Fast, efficient for simpler tasks
#   - mixtral: Complex reasoning, multi-task
# ============================================================================

# ----------------------------------------------------------------------------

# ----------------------------------------------------------------------------
